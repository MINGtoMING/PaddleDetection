{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 安装OpenXLab提供的Python库\n",
    "```shell\n",
    "pip install openxlab\n",
    "```\n",
    "访问该[链接](https://opendatalab.com)前往官网注册账号并记录下`Access Key`与`Secret Key`，并替换如下代码中相应内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 依次下载`Objects365`, `Flickr30k`和`GQA`数据集\n",
    "如遇卡顿可中段该进程重新运行(下载全程使用cache可以直接恢复下载进度)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openxlab\n",
    "from openxlab.dataset import info\n",
    "from openxlab.dataset import get\n",
    "from openxlab.dataset import download\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "access_key = '<Access Key>'\n",
    "secret_key = '<Secret Key>'\n",
    "openxlab.login(ak=access_key, sk=secret_key)\n",
    "\n",
    "\n",
    "def check(file_path: str, checksum: str):\n",
    "    assert os.path.exists(file_path), FileNotFoundError(file_path)\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as fp:\n",
    "        while chunk := fp.read(8192):\n",
    "            hasher.update(chunk)\n",
    "    assert hasher.hexdigest() == checksum\n",
    "\n",
    "\n",
    "def get_dataset(dataset: str, target_path: str):\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "    if dataset == 'obj365':\n",
    "        dataset_repo = 'OpenDataLab/Objects365_v1'\n",
    "        source_path = '/raw/Objects365_v1.tar.gz'\n",
    "        checksum = 'ca354f9e6e33f99ac16cbac900c692f2'\n",
    "    elif dataset == 'flickr':\n",
    "        dataset_repo = 'OpenDataLab/Flickr_Image'\n",
    "        source_path = '/raw/archive.zip'\n",
    "        checksum = '0acd2ed7099c62c9d0ce77941391ee2b'\n",
    "    elif dataset == 'gqa':\n",
    "        dataset_repo = 'OpenDataLab/GQA'\n",
    "        source_path = '/raw/images.zip'\n",
    "        checksum = 'ce0e89c03830722434d7f20a41b05342'\n",
    "    else:\n",
    "        raise NotImplementedError(dataset)\n",
    "\n",
    "    info(dataset_repo=dataset_repo)\n",
    "    download(dataset_repo=dataset_repo,\n",
    "             source_path=source_path,\n",
    "             target_path=target_path)\n",
    "    check(\n",
    "        os.path.join(target_path, dataset_repo.replace('/', '___'),\n",
    "                     source_path), checksum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset(dataset='obj365', target_path='data/obj365')\n",
    "get_dataset(dataset='flickr', target_path='data/flickr')\n",
    "get_dataset(dataset='gqa', target_path='data/gqa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 依次提取`Objects365`, `Flickr30k`和`GQA`数据集中的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "\n",
    "def get_images(dataset: str, target_path: str):\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "    if dataset == 'obj365':\n",
    "        tar_gz_path = './data/obj365/OpenDataLab___Objects365_v1/raw/Objects365_v1.tar.gz'\n",
    "        with tarfile.open(tar_gz_path, 'r:gz') as tar_ref:\n",
    "            for member in tar_ref.getmembers():\n",
    "                if 'train' in member.name and member.name.endswith('.zip'):\n",
    "                    zip_file = tar_ref.extractfile(member)\n",
    "                    with zipfile.ZipFile(zip_file) as zip_ref:\n",
    "                        pbar = tqdm(\n",
    "                            total=len(zip_ref.infolist()),\n",
    "                            desc=\n",
    "                            f'unzip {member.name}/train/*.jpg to {target_path}',\n",
    "                            ncols=150,\n",
    "                            unit='file')\n",
    "                        for file in zip_ref.infolist():\n",
    "                            zip_ref.extract(file, target_path)\n",
    "                            shutil.move(\n",
    "                                os.path.join(target_path, file.filename),\n",
    "                                os.path.join(target_path,\n",
    "                                             os.path.basename(file.filename)))\n",
    "                            pbar.update(1)\n",
    "                        pbar.close()\n",
    "                        shutil.rmtree(os.path.join(target_path, 'train'))\n",
    "    elif dataset == 'flickr':\n",
    "        zip_path = './data/flickr/OpenDataLab___Flickr_Image/raw/archive.zip'\n",
    "        flag = 'flickr30k_images/flickr30k_images/flickr30k_images'\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            target_files = []\n",
    "            for member in zip_ref.infolist():\n",
    "                if os.path.dirname(\n",
    "                        member.filename) == flag and member.filename.endswith(\n",
    "                            '.jpg'):\n",
    "                    target_files.append(member)\n",
    "            pbar = tqdm(total=len(target_files),\n",
    "                        desc=f'unzip {zip_path}/{flag}/*.jpg to {target_path}',\n",
    "                        unit='file',\n",
    "                        ncols=150)\n",
    "            for member in target_files:\n",
    "                zip_ref.extract(member, target_path)\n",
    "                shutil.move(\n",
    "                    os.path.join(target_path, member.filename),\n",
    "                    os.path.join(target_path,\n",
    "                                 os.path.basename(member.filename)))\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "            shutil.rmtree(os.path.join(target_path, flag.split(os.sep)[0]))\n",
    "    elif dataset == 'gqa':\n",
    "        zip_path = './data/gqa/OpenDataLab___GQA/raw/images.zip'\n",
    "        flag = 'images'\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            target_files = []\n",
    "            for member in zip_ref.infolist():\n",
    "                if os.path.dirname(\n",
    "                        member.filename) == flag and member.filename.endswith(\n",
    "                            '.jpg'):\n",
    "                    target_files.append(member)\n",
    "            pbar = tqdm(total=len(target_files),\n",
    "                        desc=f'unzip {zip_path} to {target_path}',\n",
    "                        unit='file',\n",
    "                        ncols=150)\n",
    "            for member in target_files:\n",
    "                zip_ref.extract(member, target_path)\n",
    "                shutil.move(\n",
    "                    os.path.join(target_path, member.filename),\n",
    "                    os.path.join(target_path,\n",
    "                                 os.path.basename(member.filename)))\n",
    "                pbar.update(1)\n",
    "            pbar.close()\n",
    "            shutil.rmtree(os.path.join(target_path, flag))\n",
    "    else:\n",
    "        raise NotImplementedError(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(dataset='obj365', target_path='./data/obj365/images')\n",
    "get_images(dataset='flickr', target_path='./data/flickr/images')\n",
    "get_images(dataset='gqa', target_path='./data/gqa/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(os.listdir('./data/obj365/images')) == 608606\n",
    "assert len(os.listdir('./data/flickr/images')) == 31784\n",
    "assert len(os.listdir('./data/gqa/images')) == 148854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 依次获取`Objects365`, `Flickr30k`和`GQA`数据集的标注文件\n",
    "\n",
    "`Objects365`的标注文件直接从数据集压缩包中提取。\n",
    "\n",
    "`Flickr30k`和`GQA`的标注文件需要重Huggingface的GLIP仓库中进行下载。\n",
    "\n",
    "#### 下载方式一\n",
    "\n",
    "```shell\n",
    "pushd .\n",
    "cd ./data/flickr/annotations\n",
    "wget https://huggingface.co/GLIPModel/GLIP/resolve/main/mdetr_annotations/final_flickr_separateGT_train.json\n",
    "popd\n",
    "\n",
    "pushd .\n",
    "cd ./data/gqa/annotations\n",
    "wget https://huggingface.co/GLIPModel/GLIP/resolve/main/mdetr_annotations/final_mixed_train_no_coco.json\n",
    "popd\n",
    "```\n",
    "#### 下载方式二\n",
    "\n",
    "访问[此链接](https://huggingface.co/GLIPModel/GLIP/tree/main/mdetr_annotations), 下载`final_flickr_separateGT_train.json`与`final_mixed_train_no_coco.json`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(dataset: str, target_path: str):\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "    if dataset == 'obj365':\n",
    "        tar_gz_path = './data/obj365/OpenDataLab___Objects365_v1/raw/Objects365_v1.tar.gz'\n",
    "        with tarfile.open(tar_gz_path, 'r:gz') as tar_ref:\n",
    "            for member in tar_ref.getmembers():\n",
    "                if os.path.basename(member.name) == 'objects365_train.json':\n",
    "                    tar_ref.extract(member, target_path)\n",
    "                    shutil.move(\n",
    "                        os.path.join(target_path, member.name),\n",
    "                        os.path.join(target_path,\n",
    "                                     os.path.basename(member.name)))\n",
    "                    shutil.rmtree(\n",
    "                        os.path.join(target_path,\n",
    "                                     member.name.split(os.sep)[0]))\n",
    "    else:\n",
    "        raise NotImplementedError(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_annotations(dataset='obj365', target_path='./data/obj365/annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 清理`Objects365`, `Flickr30k`和`GQA`数据集的原始文件(可选)\n",
    "清理前请确保以上步骤已全部正确执行！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./data/obj365/OpenDataLab___Objects365_v1')\n",
    "shutil.rmtree('./data/flickr/OpenDataLab___Flickr_Image')\n",
    "shutil.rmtree('./data/gqa/OpenDataLab___GQA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 打印数据集目录结构\n",
    "正确的目录结构如下：\n",
    "```txt\n",
    "data\n",
    "├── obj365\n",
    "│   ├── images\n",
    "│   │   ├── obj365_train_000000000012.jpg\n",
    "│   │   ├── obj365_train_000000000036.jpg\n",
    "│   │   ├── obj365_train_000000000072.jpg\n",
    "│   │   ├── ... 608603 more files\n",
    "│   └── annotations\n",
    "│       └── objects365_train.json\n",
    "├── flickr\n",
    "│   ├── images\n",
    "│   │   ├── 1000092795.jpg\n",
    "│   │   ├── 10002456.jpg\n",
    "│   │   ├── 1000268201.jpg\n",
    "│   │   ├── ... 31780 more files\n",
    "│   └── annotations\n",
    "│       └── final_flickr_separateGT_train.json\n",
    "└── gqa\n",
    "    ├── images\n",
    "    │   ├── 2317659.jpg\n",
    "    │   ├── 2325293.jpg\n",
    "    │   ├── n324162.jpg\n",
    "    │   ├── ... 148851 more files\n",
    "    └── annotations\n",
    "        └── final_mixed_train_no_coco.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def gen_dir_tree(target_path, prefix='', max_files=3):\n",
    "    tree = prefix + os.path.basename(target_path) + '\\n'\n",
    "    prefix = prefix.replace('├── ', '│   ').replace('└── ', '    ')\n",
    "\n",
    "    if os.path.isdir(target_path):\n",
    "        items = os.listdir(target_path)\n",
    "        items.sort(key=lambda x: os.path.isfile(os.path.join(target_path, x)))\n",
    "        for index, item in enumerate(items):\n",
    "            item_path = os.path.join(target_path, item)\n",
    "            if os.path.isfile(item_path) and index >= max_files:\n",
    "                remaining_files = len(items) - index\n",
    "                tree += prefix + '├── ... ' + str(\n",
    "                    remaining_files) + ' more files\\n'\n",
    "                break\n",
    "            if index == len(items) - 1:\n",
    "                tree += gen_dir_tree(item_path, prefix + '└── ', max_files)\n",
    "            else:\n",
    "                tree += gen_dir_tree(item_path, prefix + '├── ', max_files)\n",
    "    return tree\n",
    "\n",
    "\n",
    "def print_dir_tree(target_path, max_files=3):\n",
    "    tree = gen_dir_tree(target_path, max_files=max_files)\n",
    "    print(tree)\n",
    "\n",
    "\n",
    "print_dir_tree('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO  # type: ignore\n",
    "from tqdm import tqdm  # type: ignore\n",
    "\n",
    "obj365_ann_file = './data/obj365/annotations/objects365_train.json'\n",
    "obj365_coco = COCO(obj365_ann_file)\n",
    "obj365_img_ids = obj365_coco.getImgIds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 依次将`Objects365`, `Flickr30k`和`GQA`数据集中的有效标准信息写入`LMDB`文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import lmdb\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "obj365_ann_file = \"./data/obj365/annotations/objects365_train.json\"\n",
    "flickr_ann_file = \"./data/flickr/annotations/final_flickr_separateGT_train.json\"\n",
    "gqa_ann_file = \"./data/gqa/annotations/final_mixed_train_no_coco.json\"\n",
    "\n",
    "obj365_coco = COCO(obj365_ann_file)\n",
    "flickr_coco = COCO(flickr_ann_file)\n",
    "gqa_coco = COCO(gqa_ann_file)\n",
    "\n",
    "obj365_img_ids = obj365_coco.getImgIds()\n",
    "flickr_img_ids = flickr_coco.getImgIds()\n",
    "gqa_img_ids = gqa_coco.getImgIds()\n",
    "\n",
    "obj365_cat_ids = sorted(obj365_coco.getCatIds())\n",
    "obj365_cat_names = [\n",
    "    obj365_coco.loadCats(cat_id)[0][\"name\"] for cat_id in obj365_cat_ids\n",
    "]\n",
    "obj365_texts = [cat_name.split(\"/\") for cat_name in obj365_cat_names]\n",
    "\n",
    "env = lmdb.open(\"data/obj365_goldg_lmdb\", map_size=1024**4)\n",
    "obj365_img_dir = \"data/obj365/images\"\n",
    "flickr_img_dir = \"data/flickr/images\"\n",
    "gqa_img_dir = \"data/gqa/images\"\n",
    "eps = 1e-5\n",
    "worker_num = 8\n",
    "\n",
    "new_img_id_lock = threading.Lock()\n",
    "new_img_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_obj365(img_id, img_dir, coco_inst):\n",
    "    global new_img_id, new_ann_id\n",
    "\n",
    "    img_info = coco_inst.loadImgs([img_id])[0]\n",
    "    ann_ids = coco_inst.getAnnIds(imgIds=[img_id])\n",
    "    ann_info = coco_inst.loadAnns(ann_ids)\n",
    "\n",
    "    img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "    if not os.path.exists(img_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    im_h, im_w = im.shape[:2]\n",
    "    if im_h != float(img_info[\"height\"]) or im_w != float(img_info[\"width\"]):\n",
    "        return None\n",
    "\n",
    "    del im\n",
    "\n",
    "    rec = {\n",
    "        \"im_file\": os.path.relpath(img_path, \"./data\"),\n",
    "        \"h\": im_h,\n",
    "        \"w\": im_w,\n",
    "        \"texts\": obj365_texts,\n",
    "    }\n",
    "\n",
    "    valid_anns = []\n",
    "    for ann in ann_info:\n",
    "        if \"bbox\" not in ann:\n",
    "            continue\n",
    "        else:\n",
    "            if not any(np.array(ann[\"bbox\"])):\n",
    "                continue\n",
    "\n",
    "        if ann[\"bbox\"][2] <= eps or ann[\"bbox\"][3] <= eps:\n",
    "            continue\n",
    "\n",
    "        if ann[\"area\"] <= 0:\n",
    "            continue\n",
    "\n",
    "        valid_anns.append(ann)\n",
    "\n",
    "    valid_num = len(valid_anns)\n",
    "    if valid_num == 0:\n",
    "        return None\n",
    "\n",
    "    gt_bbox = np.zeros((valid_num, 4), dtype=np.float32)\n",
    "    gt_class = np.zeros((valid_num, 1), dtype=np.int32)\n",
    "    is_crowd = np.zeros((valid_num, 1), dtype=np.int32)\n",
    "\n",
    "    for i, ann in enumerate(valid_anns):\n",
    "        gt_class[i][0] = ann[\"category_id\"] - 1\n",
    "        x1, y1, box_w, box_h = ann[\"bbox\"]\n",
    "        x2 = x1 + box_w\n",
    "        y2 = y1 + box_h\n",
    "        gt_bbox[i, :] = [x1, y1, x2, y2]\n",
    "        is_crowd[i][0] = ann[\"iscrowd\"]\n",
    "\n",
    "    rec.update({\n",
    "        \"gt_class\": gt_class,\n",
    "        \"gt_bbox\": gt_bbox,\n",
    "        \"is_crowd\": is_crowd,\n",
    "    })\n",
    "\n",
    "    return rec\n",
    "\n",
    "\n",
    "def process_flickr(img_id, img_dir, coco_inst):\n",
    "    global new_img_id, new_ann_id\n",
    "\n",
    "    img_info = coco_inst.loadImgs([img_id])[0]\n",
    "    ann_ids = coco_inst.getAnnIds(imgIds=[img_id])\n",
    "    ann_info = coco_inst.loadAnns(ann_ids)\n",
    "\n",
    "    ann_info = [ann for ann in ann_info if len(ann[\"tokens_positive\"]) > 0]\n",
    "    if len(ann_info) == 0:\n",
    "        return None\n",
    "    ann_info = sorted(ann_info, key=lambda i: sum(i[\"tokens_positive\"][0]))\n",
    "\n",
    "    cat2id = {}\n",
    "    texts = []\n",
    "\n",
    "    valid_anns = []\n",
    "    for ann in ann_info:\n",
    "        if ann[\"bbox\"][2] <= eps or ann[\"bbox\"][3] <= eps:\n",
    "            continue\n",
    "        cat_names = []\n",
    "        end_idx = []\n",
    "        for t in ann[\"tokens_positive\"]:\n",
    "            cat_name = img_info[\"caption\"][t[0]:t[1]]\n",
    "            pattern = re.compile(r\"^(?=.*[a-zA-Z])[a-zA-Z\\d\\s]+$\")\n",
    "            if not bool(pattern.match(cat_name)):\n",
    "                continue\n",
    "            if len(end_idx) > 0 and t[0] == end_idx[-1] + 1:\n",
    "                cat_names[-1] = cat_names[-1] + \" \" + cat_name\n",
    "            else:\n",
    "                cat_names.append(cat_name)\n",
    "            end_idx.append(t[1])\n",
    "        if len(cat_names) == 0:\n",
    "            continue\n",
    "        cat_name = \"/\".join(cat_names)\n",
    "        cat_name = cat_name.lower()\n",
    "        if cat_name not in cat2id:\n",
    "            cat2id[cat_name] = len(cat2id)\n",
    "            texts.append(cat_name)\n",
    "        ann[\"cat_id\"] = len(cat2id)\n",
    "        valid_anns.append(ann)\n",
    "\n",
    "    if len(valid_anns) == 0:\n",
    "        return None\n",
    "\n",
    "    if len(texts) == 0:\n",
    "        return None\n",
    "\n",
    "    img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "    if not os.path.exists(img_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    im_h, im_w = im.shape[:2]\n",
    "    if im_h != float(img_info[\"height\"]) or im_w != float(img_info[\"width\"]):\n",
    "        return None\n",
    "\n",
    "    del im\n",
    "\n",
    "    rec = {\n",
    "        \"im_file\": os.path.relpath(img_path, \"./data\"),\n",
    "        \"h\": im_h,\n",
    "        \"w\": im_w,\n",
    "        \"texts\": [text.split(\"/\") for text in texts],\n",
    "    }\n",
    "\n",
    "    valid_num = len(valid_anns)\n",
    "    gt_bbox = np.zeros((valid_num, 4), dtype=np.float32)\n",
    "    gt_class = np.zeros((valid_num, 1), dtype=np.int32)\n",
    "    is_crowd = np.zeros((valid_num, 1), dtype=np.int32)\n",
    "\n",
    "    for i, ann in enumerate(valid_anns):\n",
    "        gt_class[i][0] = ann[\"cat_id\"] - 1\n",
    "        x1, y1, box_w, box_h = ann[\"bbox\"]\n",
    "        x2 = x1 + box_w\n",
    "        y2 = y1 + box_h\n",
    "        gt_bbox[i, :] = [x1, y1, x2, y2]\n",
    "        is_crowd[i][0] = ann[\"iscrowd\"]\n",
    "\n",
    "    rec.update({\n",
    "        \"gt_class\": gt_class,\n",
    "        \"gt_bbox\": gt_bbox,\n",
    "        \"is_crowd\": is_crowd,\n",
    "    })\n",
    "\n",
    "    return rec\n",
    "\n",
    "\n",
    "def process_gqa(img_id, img_dir, coco_inst):\n",
    "    return process_flickr(img_id, img_dir, coco_inst)\n",
    "\n",
    "\n",
    "def write_to_lmdb(rec):\n",
    "    global new_img_id\n",
    "    if rec is not None:\n",
    "        with env.begin(write=True) as txn:\n",
    "            with new_img_id_lock:\n",
    "                rec[\"im_id\"] = np.array([new_img_id])\n",
    "                txn.put(f\"{new_img_id}\".encode(), pickle.dumps(rec))\n",
    "                new_img_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=worker_num) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_obj365, img_id, obj365_img_dir, obj365_coco)\n",
    "        for img_id in obj365_img_ids\n",
    "    ]\n",
    "    for future in tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=f\"Convert obj365\",\n",
    "    ):\n",
    "        rec = future.result()\n",
    "        executor.submit(write_to_lmdb, rec)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=worker_num) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_flickr, img_id, flickr_img_dir, flickr_coco)\n",
    "        for img_id in flickr_img_ids\n",
    "    ]\n",
    "    for future in tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=f\"Convert flickr\",\n",
    "    ):\n",
    "        rec = future.result()\n",
    "        executor.submit(write_to_lmdb, rec)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=worker_num) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_gqa, img_id, gqa_img_dir, gqa_coco)\n",
    "        for img_id in gqa_img_ids\n",
    "    ]\n",
    "    for future in tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=f\"Convert gqa\",\n",
    "    ):\n",
    "        rec = future.result()\n",
    "        executor.submit(write_to_lmdb, rec)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 可视化`LMDB`文件中的标注信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import lmdb\n",
    "import pickle\n",
    "import random\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def imagedraw_textsize_c(draw, text, font=None):\n",
    "    if int(PIL.__version__.split('.')[0]) < 10:\n",
    "        tw, th = draw.textsize(text, font=font)\n",
    "    else:\n",
    "        left, top, right, bottom = draw.textbbox((0, 0), text, font=font)\n",
    "        tw, th = right - left, bottom - top\n",
    "\n",
    "    return tw, th\n",
    "\n",
    "\n",
    "env = lmdb.open(\"data/obj365_goldg_lmdb\", map_size=1024**4)\n",
    "with env.begin(write=False) as txn:\n",
    "    total_num = txn.stat()['entries']\n",
    "    for img_id in tqdm([random.randint(0, total_num) for _ in range(100)]):\n",
    "        rec = pickle.loads(txn.get(f\"{img_id}\".encode()))\n",
    "        img_path = os.path.join('./data', rec['im_file'])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        texts = rec['texts']\n",
    "\n",
    "        num_boxes = rec['gt_bbox'].shape[0]\n",
    "\n",
    "        for i in range(num_boxes):\n",
    "            xmin, ymin, xmax, ymax = list(map(int, rec['gt_bbox'][i].tolist()))\n",
    "            draw.line([(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin),\n",
    "                       (xmin, ymin)],\n",
    "                      width=2,\n",
    "                      fill=(255, 0, 0))\n",
    "            text = texts[rec['gt_class'][i].item()][0]\n",
    "            tw, th = imagedraw_textsize_c(draw, text)\n",
    "            draw.rectangle([(xmin + 1, ymin - th), (xmin + tw + 1, ymin)],\n",
    "                           fill=(255, 0, 0))\n",
    "            draw.text((xmin + 1, ymin - th), text, fill=(255, 255, 255))\n",
    "        img.save(f\"./tmp/{img_id}.jpg\")\n",
    "        # plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
